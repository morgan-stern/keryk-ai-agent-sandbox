{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Project Setup with Next.js 15",
        "description": "Initialize the project with Next.js 15 framework, configure Tailwind CSS with dark mode default, and set up the basic file structure.",
        "details": "1. Create a new Next.js 15 project using `npx create-next-app@latest keryk-ai-agent-sandbox`\n2. Configure Tailwind CSS with dark mode as default\n3. Set up the file structure according to the PRD\n4. Install required dependencies from package.json\n5. Configure environment variables\n6. Set up basic routing structure\n7. Create placeholder components\n8. Configure dark mode theme with the specified color palette\n```css\n--background: #0a0a0a\n--foreground: #ffffff\n--card: #1a1a1a\n--card-hover: #2a2a2a\n--primary: #3b82f6\n--primary-hover: #2563eb\n--text-muted: #a1a1aa\n--border: #27272a\n```",
        "testStrategy": "Verify project structure matches PRD requirements. Run the application locally to ensure it builds without errors. Confirm dark mode is working as the default theme. Validate that all required dependencies are installed correctly.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 2,
        "title": "Firebase Authentication Integration",
        "description": "Integrate Firebase Authentication to support email/password login and anonymous access for test agents.",
        "details": "1. Set up Firebase project in Firebase console\n2. Install Firebase SDK: `npm install firebase`\n3. Create `src/lib/firebase.ts` for Firebase initialization\n4. Configure Firebase Auth with email/password provider\n5. Implement anonymous authentication for test agent access\n6. Create authentication hooks for login/logout functionality\n7. Set up user context provider to share auth state\n8. Add `sandbox_access` flag check in user profile\n9. Implement protected routes for authenticated users\n10. Create login form component\n\n```typescript\n// src/lib/firebase.ts\nimport { initializeApp } from 'firebase/app';\nimport { getAuth } from 'firebase/auth';\nimport { getFirestore } from 'firebase/firestore';\n\nconst firebaseConfig = {\n  apiKey: process.env.NEXT_PUBLIC_FIREBASE_API_KEY,\n  authDomain: process.env.NEXT_PUBLIC_FIREBASE_AUTH_DOMAIN,\n  projectId: process.env.NEXT_PUBLIC_FIREBASE_PROJECT_ID,\n};\n\nconst app = initializeApp(firebaseConfig);\nconst auth = getAuth(app);\nconst db = getFirestore(app);\n\nexport { auth, db };\n```",
        "testStrategy": "Test user registration, login with email/password, and anonymous access. Verify that the `sandbox_access` flag correctly restricts access to permitted agents. Test authentication persistence across page refreshes. Ensure protected routes redirect unauthenticated users appropriately.",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 3,
        "title": "Firebase Firestore Integration for Agent Data",
        "description": "Set up Firestore database connection to fetch agent data from the Curator database with real-time updates.",
        "details": "1. Configure Firestore in the Firebase project\n2. Create agent data models and interfaces\n3. Implement `src/lib/agents.ts` with functions to fetch and query agents\n4. Set up real-time listeners for agent updates\n5. Create `useAgent` hook in `src/hooks/useAgent.ts` for component access\n6. Implement filtering and search functionality\n7. Add error handling for database connection issues\n\n```typescript\n// src/lib/agents.ts\nimport { db } from './firebase';\nimport { collection, query, where, getDocs, onSnapshot } from 'firebase/firestore';\n\nexport interface Agent {\n  id: string;\n  name: string;\n  description: string;\n  supportedModes: ('text' | 'voice')[];\n  tags: string[];\n  isTestAgent: boolean;\n}\n\nexport const getAgents = async (userId: string | null) => {\n  const agentsRef = collection(db, 'agents');\n  let q;\n  \n  if (!userId) {\n    // Anonymous users only get test agents\n    q = query(agentsRef, where('isTestAgent', '==', true));\n  } else {\n    // Get all agents for authenticated users with sandbox_access\n    q = query(agentsRef);\n  }\n  \n  const snapshot = await getDocs(q);\n  return snapshot.docs.map(doc => ({ id: doc.id, ...doc.data() }) as Agent);\n};\n\nexport const subscribeToAgents = (userId: string | null, callback: (agents: Agent[]) => void) => {\n  const agentsRef = collection(db, 'agents');\n  let q;\n  \n  if (!userId) {\n    q = query(agentsRef, where('isTestAgent', '==', true));\n  } else {\n    q = query(agentsRef);\n  }\n  \n  return onSnapshot(q, (snapshot) => {\n    const agents = snapshot.docs.map(doc => ({ id: doc.id, ...doc.data() }) as Agent);\n    callback(agents);\n  });\n};\n```",
        "testStrategy": "Test fetching agents from Firestore with both authenticated and anonymous users. Verify real-time updates work when agent data changes. Test search and filtering functionality. Ensure error handling works correctly when database is unavailable.",
        "priority": "high",
        "dependencies": [
          2
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 4,
        "title": "Landing Page and Agent Selection UI",
        "description": "Create the landing page with agent selection UI, including grid/list view, search functionality, and agent cards.",
        "details": "1. Create `src/app/page.tsx` as the landing page\n2. Implement hero section with 'Try an Agent' CTA\n3. Create `AgentCard.tsx` component for displaying agent information\n4. Implement grid/list view for agent browsing\n5. Add search input with debounced query\n6. Implement filtering by agent tags\n7. Create skeleton loading states for agent cards\n8. Add responsive layout for all screen sizes\n9. Implement touch-friendly UI elements\n\n```typescript\n// src/components/AgentCard.tsx\nimport { Card } from '@keryk-mentor/shared';\nimport { Agent } from '@/lib/agents';\n\ninterface AgentCardProps {\n  agent: Agent;\n  onClick: (agent: Agent) => void;\n}\n\nexport function AgentCard({ agent, onClick }: AgentCardProps) {\n  return (\n    <Card \n      className=\"p-4 cursor-pointer hover:bg-card-hover transition-colors\"\n      onClick={() => onClick(agent)}\n    >\n      <h3 className=\"text-lg font-medium mb-2\">{agent.name}</h3>\n      <p className=\"text-text-muted text-sm mb-3\">{agent.description}</p>\n      <div className=\"flex gap-2\">\n        {agent.supportedModes.map(mode => (\n          <span \n            key={mode}\n            className=\"px-2 py-1 bg-primary/10 text-primary rounded text-xs\"\n          >\n            {mode}\n          </span>\n        ))}\n      </div>\n    </Card>\n  );\n}\n```",
        "testStrategy": "Test responsive layout on various screen sizes. Verify search and filtering functionality works correctly. Test loading states and transitions. Ensure touch targets meet the 44px minimum requirement. Verify agent cards display all required information correctly.",
        "priority": "high",
        "dependencies": [
          1,
          3
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 5,
        "title": "Chat Interface Layout and Routing",
        "description": "Create the chat interface layout and implement routing between agent selection and chat pages.",
        "details": "1. Create `src/app/chat/[agentId]/page.tsx` for the chat interface\n2. Implement chat layout with header, message area, and input\n3. Set up dynamic routing with agent ID parameter\n4. Create navigation between agent selection and chat\n5. Implement back button and agent info in header\n6. Create responsive layout for all screen sizes\n7. Handle mobile keyboard appearance\n8. Add proper meta viewport tags\n\n```typescript\n// src/app/chat/[agentId]/page.tsx\nimport { Suspense } from 'react';\nimport { ChatInterface } from '@/components/ChatInterface';\nimport { getAgent } from '@/lib/agents';\n\nexport default async function ChatPage({ params }: { params: { agentId: string } }) {\n  return (\n    <div className=\"flex flex-col h-screen bg-background\">\n      <Suspense fallback={<div>Loading...</div>}>\n        <ChatInterface agentId={params.agentId} />\n      </Suspense>\n    </div>\n  );\n}\n\n// In layout.tsx or a component that needs viewport handling\nexport const metadata = {\n  viewport: 'width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0'\n};\n```",
        "testStrategy": "Test navigation between agent selection and chat pages. Verify dynamic routing works with different agent IDs. Test responsive layout on various screen sizes. Ensure mobile keyboard handling works correctly. Verify back button functionality.",
        "priority": "high",
        "dependencies": [
          1,
          4
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 6,
        "title": "Text Chat Message Component",
        "description": "Implement the text chat message component with message bubbles, typing indicators, and auto-scroll functionality.",
        "details": "1. Create `src/components/TextChat.tsx` component\n2. Implement message bubble UI with user/agent distinction\n3. Create typing indicator animation\n4. Implement auto-scroll to keep latest messages visible\n5. Add copy support with long-press\n6. Create message list with proper spacing\n7. Implement scroll area with proper touch handling\n\n```typescript\n// src/components/TextChat.tsx\nimport { useRef, useEffect } from 'react';\nimport { ScrollArea } from '@keryk-mentor/shared';\n\ninterface Message {\n  id: string;\n  content: string;\n  sender: 'user' | 'agent';\n  timestamp: number;\n}\n\ninterface TextChatProps {\n  messages: Message[];\n  isTyping: boolean;\n}\n\nexport function TextChat({ messages, isTyping }: TextChatProps) {\n  const scrollRef = useRef<HTMLDivElement>(null);\n  \n  // Auto-scroll to bottom when new messages arrive\n  useEffect(() => {\n    if (scrollRef.current) {\n      scrollRef.current.scrollTop = scrollRef.current.scrollHeight;\n    }\n  }, [messages]);\n\n  return (\n    <ScrollArea className=\"flex-1 p-4\" ref={scrollRef}>\n      <div className=\"flex flex-col gap-2\">\n        {messages.map((message) => (\n          <div \n            key={message.id}\n            className={`max-w-[80%] p-3 rounded-lg ${message.sender === 'user' ? \n              'bg-primary text-white self-end rounded-br-none' : \n              'bg-card text-foreground self-start rounded-bl-none'}`}\n          >\n            {message.content}\n          </div>\n        ))}\n        {isTyping && (\n          <div className=\"bg-card text-foreground self-start rounded-lg rounded-bl-none p-3 max-w-[80%]\">\n            <span className=\"typing-indicator\">•••</span>\n          </div>\n        )}\n      </div>\n    </ScrollArea>\n  );\n}\n```",
        "testStrategy": "Test message rendering with various content lengths. Verify auto-scroll functionality works with new messages. Test typing indicator appearance and animation. Ensure copy functionality works on long-press. Test on various screen sizes to verify responsive behavior.",
        "priority": "medium",
        "dependencies": [
          5
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 7,
        "title": "Text Chat Input Component",
        "description": "Create the text input component for sending messages with proper mobile keyboard handling.",
        "status": "done",
        "dependencies": [
          5
        ],
        "priority": "medium",
        "details": "1. Create text input component with send button\n2. Handle form submission and input clearing\n3. Implement proper mobile keyboard handling\n4. Add input focus management\n5. Create disabled state for when agent is processing\n6. Implement character limit with visual indicator\n7. Use auto-resizing textarea that grows with content\n8. Support Enter to send, Shift+Enter for new line\n9. Ensure minimum 48px height for touch targets\n10. Add smooth animations and transitions\n11. Keep focus after sending for continuous messaging\n\n```typescript\n// src/components/TextChatInput.tsx\nimport { useState, FormEvent, KeyboardEvent, useRef, useEffect } from 'react';\nimport { Button } from '@keryk-mentor/shared';\n\ninterface TextChatInputProps {\n  onSendMessage: (message: string) => void;\n  disabled?: boolean;\n  autoFocus?: boolean;\n  maxLength?: number;\n}\n\nexport function TextChatInput({ \n  onSendMessage, \n  disabled = false, \n  autoFocus = false,\n  maxLength = 1000 \n}: TextChatInputProps) {\n  const [message, setMessage] = useState('');\n  const textareaRef = useRef<HTMLTextAreaElement>(null);\n\n  // Auto-resize textarea as content grows\n  useEffect(() => {\n    if (textareaRef.current) {\n      textareaRef.current.style.height = 'auto';\n      textareaRef.current.style.height = `${textareaRef.current.scrollHeight}px`;\n    }\n  }, [message]);\n\n  const handleSubmit = (e: FormEvent) => {\n    e.preventDefault();\n    if (message.trim() && !disabled) {\n      onSendMessage(message.trim());\n      setMessage('');\n      // Keep focus on textarea after sending\n      setTimeout(() => textareaRef.current?.focus(), 0);\n    }\n  };\n\n  const handleKeyDown = (e: KeyboardEvent<HTMLTextAreaElement>) => {\n    if (e.key === 'Enter' && !e.shiftKey) {\n      e.preventDefault();\n      handleSubmit(e as unknown as FormEvent);\n    }\n  };\n\n  const charactersRemaining = maxLength - message.length;\n  const isNearLimit = charactersRemaining < maxLength * 0.1;\n\n  return (\n    <form \n      onSubmit={handleSubmit}\n      className=\"flex items-center gap-2 p-4 border-t border-border bg-background transition-all duration-200\"\n    >\n      <div className=\"relative flex-1\">\n        <textarea\n          ref={textareaRef}\n          value={message}\n          onChange={(e) => setMessage(e.target.value)}\n          onKeyDown={handleKeyDown}\n          placeholder=\"Type your message...\"\n          disabled={disabled}\n          maxLength={maxLength}\n          autoFocus={autoFocus}\n          rows={1}\n          style={{ fontSize: '16px' }} // Prevents iOS zoom on focus\n          className=\"w-full min-h-[48px] bg-card rounded-md p-3 text-foreground focus:outline-none focus:ring-1 focus:ring-primary resize-none transition-all duration-200\"\n        />\n        {maxLength && (\n          <div className={`text-xs absolute bottom-1 right-2 transition-opacity duration-200 ${isNearLimit ? 'text-warning' : 'text-muted-foreground'} ${message.length > 0 ? 'opacity-100' : 'opacity-0'}`}>\n            {charactersRemaining}\n          </div>\n        )}\n      </div>\n      <Button \n        type=\"submit\" \n        disabled={!message.trim() || disabled}\n        className=\"h-[48px] w-[48px] flex items-center justify-center transition-all duration-200\"\n        aria-label=\"Send message\"\n      >\n        Send\n      </Button>\n    </form>\n  );\n}\n```",
        "testStrategy": "1. Test input submission with various message lengths\n2. Verify form clears after submission and focus remains in the textarea\n3. Test disabled state when agent is processing\n4. Ensure mobile keyboard appears and dismisses correctly\n5. Verify touch targets meet the 48px minimum requirement\n6. Test auto-resizing functionality with different content lengths\n7. Verify Enter sends message while Shift+Enter creates a new line\n8. Test character limit functionality and visual indicator\n9. Ensure smooth animations and transitions work as expected\n10. Test autoFocus prop functionality",
        "subtasks": []
      },
      {
        "id": 8,
        "title": "Agent Integration for Text Chat",
        "description": "Implement the integration with the StandardizedAgent API for text-based conversations.",
        "status": "done",
        "dependencies": [
          3,
          6,
          7
        ],
        "priority": "high",
        "details": "1. Create agent message handling service\n2. Implement message sending and receiving\n3. Create message state management\n4. Handle agent responses and typing indicators\n5. Implement error handling for failed requests\n6. Create message queue for offline support\n\nImplementation includes:\n\n1. useAgentChat hook for:\n   - Message sending and receiving with agent API\n   - Online/offline detection and queue management\n   - Message status tracking (sending, sent, failed)\n   - Retry logic for failed messages\n   - Typing indicators and processing states\n   - Request cancellation support\n\n2. agentService for clean separation of concerns:\n   - Session management\n   - Message sending with error handling\n   - Metadata support for agent responses\n   - Session tracking and statistics\n\n3. TextChatInterface component that combines:\n   - TextChat component for message display\n   - TextChatInput component for message input\n   - Offline/online status indicators\n   - Failed message notifications\n   - Pending message indicators\n   - Proper integration with useAgentChat hook\n\n```typescript\n// src/hooks/useAgentChat.ts\nimport { useState, useCallback, useEffect } from 'react';\nimport { agentService } from '../services/agentService';\n\ninterface Message {\n  id: string;\n  content: string;\n  sender: 'user' | 'agent';\n  timestamp: number;\n  status?: 'sending' | 'sent' | 'failed';\n  metadata?: Record<string, any>;\n}\n\nexport function useAgentChat(agentId: string) {\n  const [messages, setMessages] = useState<Message[]>([]);\n  const [isProcessing, setIsProcessing] = useState(false);\n  const [offlineQueue, setOfflineQueue] = useState<Message[]>([]);\n  const [isOnline, setIsOnline] = useState(typeof navigator !== 'undefined' ? navigator.onLine : true);\n  const [isTyping, setIsTyping] = useState(false);\n  const [abortController, setAbortController] = useState<AbortController | null>(null);\n\n  // Handle online/offline status\n  useEffect(() => {\n    const handleOnline = () => setIsOnline(true);\n    const handleOffline = () => setIsOnline(false);\n\n    window.addEventListener('online', handleOnline);\n    window.addEventListener('offline', handleOffline);\n\n    return () => {\n      window.removeEventListener('online', handleOnline);\n      window.removeEventListener('offline', handleOffline);\n    };\n  }, []);\n\n  // Process offline queue when back online\n  useEffect(() => {\n    if (isOnline && offlineQueue.length > 0 && !isProcessing) {\n      // Process queue\n      const processQueue = async () => {\n        setIsProcessing(true);\n        try {\n          for (const message of offlineQueue) {\n            await sendMessage(message.content);\n          }\n          setOfflineQueue([]);\n        } finally {\n          setIsProcessing(false);\n        }\n      };\n      processQueue();\n    }\n  }, [isOnline, offlineQueue, isProcessing]);\n\n  const retryMessage = useCallback((messageId: string) => {\n    const failedMessage = messages.find(msg => msg.id === messageId && msg.status === 'failed');\n    if (failedMessage) {\n      sendMessage(failedMessage.content);\n      // Remove the failed message\n      setMessages(prev => prev.filter(msg => msg.id !== messageId));\n    }\n  }, [messages]);\n\n  const cancelRequest = useCallback(() => {\n    if (abortController) {\n      abortController.abort();\n      setAbortController(null);\n      setIsTyping(false);\n      setIsProcessing(false);\n    }\n  }, [abortController]);\n\n  const sendMessage = useCallback(async (content: string) => {\n    // Cancel any ongoing request\n    if (abortController) {\n      abortController.abort();\n    }\n    \n    const newController = new AbortController();\n    setAbortController(newController);\n\n    const userMessage: Message = {\n      id: Date.now().toString(),\n      content,\n      sender: 'user',\n      timestamp: Date.now(),\n      status: isOnline ? 'sending' : 'failed'\n    };\n\n    setMessages(prev => [...prev, userMessage]);\n\n    if (!isOnline) {\n      setOfflineQueue(prev => [...prev, userMessage]);\n      return;\n    }\n\n    setIsProcessing(true);\n    setIsTyping(true);\n    \n    try {\n      // Update user message status to sending\n      setMessages(prev => prev.map(msg => \n        msg.id === userMessage.id ? { ...msg, status: 'sending' } : msg\n      ));\n      \n      const response = await agentService.sendMessage(agentId, content, newController.signal);\n      \n      // Update user message status\n      setMessages(prev => prev.map(msg => \n        msg.id === userMessage.id ? { ...msg, status: 'sent' } : msg\n      ));\n\n      // Add agent response\n      setMessages(prev => [...prev, {\n        id: Date.now().toString(),\n        content: response.message,\n        sender: 'agent',\n        timestamp: Date.now(),\n        metadata: response.metadata\n      }]);\n    } catch (error) {\n      if ((error as Error).name !== 'AbortError') {\n        console.error('Error sending message:', error);\n        // Update message status to failed\n        setMessages(prev => prev.map(msg => \n          msg.id === userMessage.id ? { ...msg, status: 'failed' } : msg\n        ));\n      }\n    } finally {\n      setIsTyping(false);\n      setIsProcessing(false);\n      setAbortController(null);\n    }\n  }, [agentId, isOnline, abortController]);\n\n  return { \n    messages, \n    sendMessage, \n    isProcessing, \n    isTyping, \n    isOnline, \n    retryMessage,\n    cancelRequest\n  };\n}\n```",
        "testStrategy": "Test sending and receiving messages with the agent API. Verify typing indicators work correctly. Test error handling with simulated API failures. Test offline message queuing and sending when back online. Verify message state updates correctly throughout the process. Test retry functionality for failed messages. Test request cancellation. Verify TextChatInterface components display correct status indicators. Test session management in agentService.",
        "subtasks": [
          {
            "id": 1,
            "title": "Create useAgentChat hook",
            "description": "Implement hook for message handling with agent API, including online/offline detection, message status tracking, retry logic, typing indicators, and request cancellation.",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Create agentService",
            "description": "Implement service for session management, message sending with error handling, metadata support, and session tracking/statistics.",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Create TextChatInterface component",
            "description": "Implement component that combines TextChat for message display, TextChatInput for message input, status indicators, and integration with useAgentChat hook.",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Write unit tests for useAgentChat hook",
            "description": "Test message sending/receiving, offline queue, retry logic, and request cancellation.",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Write unit tests for agentService",
            "description": "Test session management, error handling, and metadata support.",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Write integration tests for TextChatInterface",
            "description": "Test the complete flow from user input to message display with various states (online/offline, success/failure).",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 9,
        "title": "Voice Chat UI Components",
        "description": "Create the voice chat UI components with visual feedback for voice activity.",
        "details": "1. Create `src/components/VoiceChat.tsx` component\n2. Implement waveform or pulse animation for voice activity\n3. Create visual indicators for listening/speaking states\n4. Add mode indicator showing voice is active\n5. Implement visual feedback for voice detection\n\n```typescript\n// src/components/VoiceChat.tsx\nimport { useState, useEffect } from 'react';\n\ninterface VoiceChatProps {\n  isListening: boolean;\n  isSpeaking: boolean;\n  transcript: string;\n  lastAgentMessage: string;\n}\n\nexport function VoiceChat({ isListening, isSpeaking, transcript, lastAgentMessage }: VoiceChatProps) {\n  return (\n    <div className=\"flex flex-col items-center justify-center flex-1 p-4\">\n      <div className=\"mb-8 text-center\">\n        <p className=\"text-text-muted mb-2\">\n          {isListening ? 'Listening...' : isSpeaking ? 'Agent speaking...' : 'Ready'}\n        </p>\n        \n        {/* Voice activity visualization */}\n        <div className=\"flex items-center justify-center h-16 mb-4\">\n          {isListening && (\n            <div className=\"flex items-end space-x-1 h-full\">\n              {[...Array(10)].map((_, i) => (\n                <div \n                  key={i}\n                  className=\"bg-primary w-2 rounded-full animate-pulse\"\n                  style={{\n                    height: `${Math.random() * 100}%`,\n                    animationDelay: `${i * 0.1}s`\n                  }}\n                />\n              ))}\n            </div>\n          )}\n          \n          {isSpeaking && (\n            <div className=\"w-16 h-16 rounded-full bg-primary/20 flex items-center justify-center\">\n              <div className=\"w-12 h-12 rounded-full bg-primary animate-pulse\" />\n            </div>\n          )}\n          \n          {!isListening && !isSpeaking && (\n            <div className=\"w-16 h-16 rounded-full bg-card flex items-center justify-center\">\n              <div className=\"w-8 h-8 rounded-full bg-primary/20\" />\n            </div>\n          )}\n        </div>\n      </div>\n      \n      {/* Transcript display */}\n      {transcript && (\n        <div className=\"bg-card p-4 rounded-lg w-full max-w-md mb-4\">\n          <p className=\"text-sm text-text-muted mb-1\">You said:</p>\n          <p>{transcript}</p>\n        </div>\n      )}\n      \n      {/* Last agent message */}\n      {lastAgentMessage && (\n        <div className=\"bg-primary/10 p-4 rounded-lg w-full max-w-md\">\n          <p className=\"text-sm text-text-muted mb-1\">Agent said:</p>\n          <p>{lastAgentMessage}</p>\n        </div>\n      )}\n    </div>\n  );\n}\n```",
        "testStrategy": "Test visual feedback components in different states (listening, speaking, idle). Verify animations work correctly. Test responsive layout on various screen sizes. Ensure transcript and agent message displays update correctly.",
        "priority": "medium",
        "dependencies": [
          5
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 10,
        "title": "OpenAI Realtime API Integration",
        "description": "Implement the integration with OpenAI's Realtime API for voice conversations.",
        "details": "1. Create `src/hooks/useRealtimeVoice.ts` hook\n2. Implement WebSocket connection to OpenAI Realtime API\n3. Set up audio recording and streaming\n4. Handle voice activity detection\n5. Implement continuous listening mode\n6. Add interruption support for natural conversation\n7. Handle audio permissions\n\n```typescript\n// src/hooks/useRealtimeVoice.ts\nimport { useState, useEffect, useCallback } from 'react';\n\nexport function useRealtimeVoice(agentId: string) {\n  const [isListening, setIsListening] = useState(false);\n  const [isSpeaking, setIsSpeaking] = useState(false);\n  const [transcript, setTranscript] = useState('');\n  const [lastAgentMessage, setLastAgentMessage] = useState('');\n  const [error, setError] = useState<string | null>(null);\n  const [socket, setSocket] = useState<WebSocket | null>(null);\n  const [audioContext, setAudioContext] = useState<AudioContext | null>(null);\n  const [mediaStream, setMediaStream] = useState<MediaStream | null>(null);\n  \n  // Initialize audio context and request permissions\n  const initializeAudio = useCallback(async () => {\n    try {\n      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n      const context = new AudioContext();\n      setMediaStream(stream);\n      setAudioContext(context);\n      return true;\n    } catch (err) {\n      setError('Microphone access denied');\n      return false;\n    }\n  }, []);\n  \n  // Start voice chat session\n  const startVoiceChat = useCallback(async () => {\n    if (!audioContext) {\n      const initialized = await initializeAudio();\n      if (!initialized) return;\n    }\n    \n    // Connect to OpenAI Realtime API\n    const ws = new WebSocket('wss://api.openai.com/v1/audio/realtime');\n    \n    ws.onopen = () => {\n      // Send initial configuration\n      ws.send(JSON.stringify({\n        type: 'config',\n        agent_id: agentId,\n        encoding: 'linear16',\n        sample_rate: 16000\n      }));\n      setIsListening(true);\n    };\n    \n    ws.onmessage = (event) => {\n      const data = JSON.parse(event.data);\n      \n      if (data.type === 'transcript') {\n        setTranscript(data.text);\n      } else if (data.type === 'audio') {\n        // Handle incoming audio from agent\n        playAudio(data.audio);\n        setIsSpeaking(true);\n      } else if (data.type === 'message') {\n        setLastAgentMessage(data.text);\n      } else if (data.type === 'error') {\n        setError(data.message);\n      } else if (data.type === 'audio_end') {\n        setIsSpeaking(false);\n      }\n    };\n    \n    ws.onerror = (err) => {\n      setError('Connection error');\n      setIsListening(false);\n    };\n    \n    ws.onclose = () => {\n      setIsListening(false);\n      setIsSpeaking(false);\n    };\n    \n    setSocket(ws);\n    \n    // Start streaming audio to the server\n    startAudioStream(ws);\n  }, [agentId, audioContext, initializeAudio]);\n  \n  // Start streaming audio from microphone to server\n  const startAudioStream = useCallback((ws: WebSocket) => {\n    if (!mediaStream || !audioContext) return;\n    \n    const source = audioContext.createMediaStreamSource(mediaStream);\n    const processor = audioContext.createScriptProcessor(4096, 1, 1);\n    \n    processor.onaudioprocess = (e) => {\n      if (ws.readyState === WebSocket.OPEN && isListening && !isSpeaking) {\n        const audioData = e.inputBuffer.getChannelData(0);\n        ws.send(audioData);\n      }\n    };\n    \n    source.connect(processor);\n    processor.connect(audioContext.destination);\n    \n    return () => {\n      source.disconnect();\n      processor.disconnect();\n    };\n  }, [mediaStream, audioContext, isListening, isSpeaking]);\n  \n  // Play audio received from the server\n  const playAudio = useCallback((audioData: ArrayBuffer) => {\n    if (!audioContext) return;\n    \n    audioContext.decodeAudioData(audioData, (buffer) => {\n      const source = audioContext.createBufferSource();\n      source.buffer = buffer;\n      source.connect(audioContext.destination);\n      source.start(0);\n      \n      source.onended = () => {\n        setIsSpeaking(false);\n      };\n    });\n  }, [audioContext]);\n  \n  // Stop voice chat\n  const stopVoiceChat = useCallback(() => {\n    if (socket) {\n      socket.close();\n      setSocket(null);\n    }\n    setIsListening(false);\n    setIsSpeaking(false);\n  }, [socket]);\n  \n  // Clean up on unmount\n  useEffect(() => {\n    return () => {\n      if (socket) socket.close();\n      if (mediaStream) {\n        mediaStream.getTracks().forEach(track => track.stop());\n      }\n    };\n  }, [socket, mediaStream]);\n  \n  return {\n    isListening,\n    isSpeaking,\n    transcript,\n    lastAgentMessage,\n    error,\n    startVoiceChat,\n    stopVoiceChat\n  };\n}\n```",
        "testStrategy": "Test audio permission requests and handling. Verify WebSocket connection to OpenAI Realtime API. Test voice activity detection. Verify continuous listening mode works correctly. Test interruption support during conversation. Ensure error handling works for various failure scenarios.",
        "priority": "high",
        "dependencies": [
          9
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 11,
        "title": "Mode Toggle Component",
        "description": "Create a component to toggle between text and voice chat modes with smooth transitions.",
        "details": "1. Create `src/components/ModeToggle.tsx` component\n2. Implement toggle button with clear visual indicators\n3. Add smooth transitions between modes\n4. Handle mode-specific initialization\n5. Create touch-friendly UI elements\n\n```typescript\n// src/components/ModeToggle.tsx\nimport { useState } from 'react';\nimport { Button } from '@keryk-mentor/shared';\n\ninterface ModeToggleProps {\n  mode: 'text' | 'voice';\n  onModeChange: (mode: 'text' | 'voice') => void;\n  supportedModes: ('text' | 'voice')[];\n  disabled?: boolean;\n}\n\nexport function ModeToggle({ mode, onModeChange, supportedModes, disabled = false }: ModeToggleProps) {\n  if (supportedModes.length <= 1) return null;\n  \n  return (\n    <div className=\"flex rounded-full bg-card p-1 w-fit\">\n      {supportedModes.includes('text') && (\n        <Button\n          variant={mode === 'text' ? 'default' : 'ghost'}\n          className={`rounded-full h-[44px] px-4 ${mode === 'text' ? 'bg-primary text-white' : 'text-text-muted'}`}\n          onClick={() => onModeChange('text')}\n          disabled={disabled}\n        >\n          <span className=\"mr-2\">💬</span>\n          Text\n        </Button>\n      )}\n      \n      {supportedModes.includes('voice') && (\n        <Button\n          variant={mode === 'voice' ? 'default' : 'ghost'}\n          className={`rounded-full h-[44px] px-4 ${mode === 'voice' ? 'bg-primary text-white' : 'text-text-muted'}`}\n          onClick={() => onModeChange('voice')}\n          disabled={disabled}\n        >\n          <span className=\"mr-2\">🎤</span>\n          Voice\n        </Button>\n      )}\n    </div>\n  );\n}\n```",
        "testStrategy": "Test mode switching between text and voice. Verify visual indicators update correctly. Test disabled state. Ensure touch targets meet the 44px minimum requirement. Verify component only shows supported modes.",
        "priority": "medium",
        "dependencies": [
          6,
          9
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 12,
        "title": "Main Chat Interface Component",
        "description": "Create the main chat interface component that combines text and voice chat functionality.",
        "details": "1. Create `src/components/ChatInterface.tsx` component\n2. Integrate text and voice chat components\n3. Implement mode switching logic\n4. Add agent information display\n5. Create header with back button\n6. Handle initialization for both modes\n\n```typescript\n// src/components/ChatInterface.tsx\nimport { useState, useEffect } from 'react';\nimport { useRouter } from 'next/navigation';\nimport { Button } from '@keryk-mentor/shared';\nimport { TextChat } from './TextChat';\nimport { TextChatInput } from './TextChatInput';\nimport { VoiceChat } from './VoiceChat';\nimport { ModeToggle } from './ModeToggle';\nimport { useAgent } from '@/hooks/useAgent';\nimport { useMessageQueue } from '@/hooks/useMessageQueue';\nimport { useRealtimeVoice } from '@/hooks/useRealtimeVoice';\n\ninterface ChatInterfaceProps {\n  agentId: string;\n}\n\nexport function ChatInterface({ agentId }: ChatInterfaceProps) {\n  const router = useRouter();\n  const { agent, isLoading: isAgentLoading } = useAgent(agentId);\n  const [mode, setMode] = useState<'text' | 'voice'>('text');\n  const { messages, sendMessage, isProcessing } = useMessageQueue(agentId);\n  const { \n    isListening, \n    isSpeaking, \n    transcript, \n    lastAgentMessage, \n    error: voiceError, \n    startVoiceChat, \n    stopVoiceChat \n  } = useRealtimeVoice(agentId);\n\n  // Initialize voice chat when switching to voice mode\n  useEffect(() => {\n    if (mode === 'voice') {\n      startVoiceChat();\n    } else {\n      stopVoiceChat();\n    }\n  }, [mode, startVoiceChat, stopVoiceChat]);\n\n  // Handle mode change\n  const handleModeChange = (newMode: 'text' | 'voice') => {\n    if (newMode === mode) return;\n    setMode(newMode);\n  };\n\n  if (isAgentLoading) {\n    return <div className=\"flex items-center justify-center h-screen\">Loading agent...</div>;\n  }\n\n  if (!agent) {\n    return <div className=\"flex items-center justify-center h-screen\">Agent not found</div>;\n  }\n\n  return (\n    <div className=\"flex flex-col h-screen bg-background\">\n      {/* Header */}\n      <header className=\"flex items-center justify-between p-4 border-b border-border\">\n        <Button \n          variant=\"ghost\" \n          onClick={() => router.push('/')}\n          className=\"h-[44px] w-[44px]\"\n        >\n          Back\n        </Button>\n        \n        <div className=\"text-center\">\n          <h1 className=\"text-lg font-medium\">{agent.name}</h1>\n        </div>\n        \n        <ModeToggle \n          mode={mode} \n          onModeChange={handleModeChange} \n          supportedModes={agent.supportedModes}\n          disabled={isProcessing || isListening || isSpeaking}\n        />\n      </header>\n\n      {/* Chat Content */}\n      <div className=\"flex-1 overflow-hidden\">\n        {mode === 'text' ? (\n          <TextChat \n            messages={messages} \n            isTyping={isProcessing} \n          />\n        ) : (\n          <VoiceChat \n            isListening={isListening}\n            isSpeaking={isSpeaking}\n            transcript={transcript}\n            lastAgentMessage={lastAgentMessage}\n          />\n        )}\n      </div>\n\n      {/* Input Area - only show for text mode */}\n      {mode === 'text' && (\n        <TextChatInput \n          onSendMessage={sendMessage} \n          disabled={isProcessing} \n        />\n      )}\n    </div>\n  );\n}\n```",
        "testStrategy": "Test integration of text and voice components. Verify mode switching works correctly. Test agent information display. Ensure back button navigation works. Test initialization for both text and voice modes. Verify error handling for both modes.",
        "priority": "high",
        "dependencies": [
          6,
          7,
          8,
          9,
          10,
          11
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 13,
        "title": "API Routes for Agent Communication",
        "description": "Create API routes for agent communication, including agent listing and message handling.",
        "details": "1. Create `src/app/api/agents/route.ts` for agent listing\n2. Implement `src/app/api/agents/[agentId]/message/route.ts` for message handling\n3. Add authentication middleware\n4. Implement rate limiting\n5. Add error handling\n6. Configure CORS for app domain only\n\n```typescript\n// src/app/api/agents/route.ts\nimport { NextResponse } from 'next/server';\nimport { getAgents } from '@/lib/agents';\nimport { auth } from '@/lib/firebase-admin';\n\nexport async function GET(request: Request) {\n  try {\n    // Get auth token from request\n    const authHeader = request.headers.get('Authorization');\n    const token = authHeader?.split('Bearer ')[1];\n    \n    let userId = null;\n    let hasAccess = false;\n    \n    if (token) {\n      try {\n        const decodedToken = await auth.verifyIdToken(token);\n        userId = decodedToken.uid;\n        \n        // Check if user has sandbox access\n        const userRecord = await auth.getUser(userId);\n        hasAccess = userRecord.customClaims?.sandbox_access === true;\n      } catch (error) {\n        // Invalid token, continue as anonymous\n      }\n    }\n    \n    // Only allow access if user has sandbox_access or we're getting test agents\n    if (!hasAccess && userId !== null) {\n      return NextResponse.json({ error: 'Unauthorized' }, { status: 403 });\n    }\n    \n    const agents = await getAgents(userId);\n    return NextResponse.json({ agents });\n  } catch (error) {\n    console.error('Error fetching agents:', error);\n    return NextResponse.json({ error: 'Internal server error' }, { status: 500 });\n  }\n}\n\n// src/app/api/agents/[agentId]/message/route.ts\nimport { NextResponse } from 'next/server';\nimport { auth } from '@/lib/firebase-admin';\n\nexport async function POST(request: Request, { params }: { params: { agentId: string } }) {\n  try {\n    const { agentId } = params;\n    const { message } = await request.json();\n    \n    // Validate message\n    if (!message || typeof message !== 'string') {\n      return NextResponse.json({ error: 'Invalid message' }, { status: 400 });\n    }\n    \n    // Get auth token from request\n    const authHeader = request.headers.get('Authorization');\n    const token = authHeader?.split('Bearer ')[1];\n    \n    let userId = null;\n    let hasAccess = false;\n    \n    if (token) {\n      try {\n        const decodedToken = await auth.verifyIdToken(token);\n        userId = decodedToken.uid;\n        \n        // Check if user has sandbox access\n        const userRecord = await auth.getUser(userId);\n        hasAccess = userRecord.customClaims?.sandbox_access === true;\n      } catch (error) {\n        // Invalid token, continue as anonymous\n      }\n    }\n    \n    // Check if agent is accessible to this user\n    // For anonymous users, only test agents are accessible\n    // For authenticated users, they need sandbox_access\n    \n    // Call agent API or service here\n    // This is a placeholder for the actual agent integration\n    const response = `This is a response from agent ${agentId} to message: ${message}`;\n    \n    return NextResponse.json({ response });\n  } catch (error) {\n    console.error('Error processing message:', error);\n    return NextResponse.json({ error: 'Internal server error' }, { status: 500 });\n  }\n}\n```",
        "testStrategy": "Test agent listing API with authenticated and anonymous users. Verify message handling API correctly processes requests. Test authentication middleware. Verify rate limiting works correctly. Test error handling with various error scenarios. Ensure CORS is properly configured.",
        "priority": "high",
        "dependencies": [
          2,
          3
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 14,
        "title": "Mobile Optimizations",
        "description": "Implement mobile-specific optimizations for touch interactions, keyboard handling, and viewport management.",
        "details": "1. Configure viewport meta tags\n2. Implement touch-action CSS properties\n3. Add swipe gestures for mode switching\n4. Optimize for virtual keyboard appearance\n5. Implement proper keyboard dismissal\n6. Add double-tap zoom prevention\n7. Optimize tap response times\n\n```typescript\n// In src/app/layout.tsx\nimport { Metadata } from 'next';\n\nexport const metadata: Metadata = {\n  title: 'Keryk AI Agent Sandbox',\n  description: 'Demo platform for Keryk AI agents',\n  viewport: 'width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0'\n};\n\n// Add to global CSS\n/*\n:root {\n  touch-action: pan-x pan-y;\n}\n\n.prevent-zoom {\n  touch-action: manipulation;\n}\n\n.chat-input {\n  /* Prevent iOS zoom on focus */\n  font-size: 16px;\n}\n\n/* Add to component CSS */\n.swipe-area {\n  touch-action: pan-x;\n}\n*/\n\n// Add keyboard handling to TextChatInput\nconst handleFocus = () => {\n  // On mobile, scroll to ensure input is visible above keyboard\n  setTimeout(() => {\n    window.scrollTo(0, document.body.scrollHeight);\n  }, 300);\n};\n\n// Add to input element\n<input\n  onFocus={handleFocus}\n  className=\"chat-input\"\n  // other props\n/>\n```",
        "testStrategy": "Test on various mobile devices to verify touch interactions work correctly. Test virtual keyboard appearance and dismissal. Verify swipe gestures for mode switching. Ensure double-tap zoom prevention works. Test tap response times for touch interactions.",
        "priority": "medium",
        "dependencies": [
          5,
          6,
          7,
          12
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 15,
        "title": "Performance Optimizations",
        "description": "Implement performance optimizations for fast loading and smooth interactions.",
        "details": "1. Implement lazy loading for agent images\n2. Add virtual scrolling for agent list\n3. Implement debounced search input\n4. Optimize component re-renders\n5. Add skeleton loading states\n6. Implement code splitting\n7. Configure bundle optimization\n\n```typescript\n// Lazy loading images example\nimport Image from 'next/image';\n\n<Image \n  src={agent.imageUrl} \n  alt={agent.name}\n  width={64}\n  height={64}\n  loading=\"lazy\"\n/>\n\n// Debounced search input\nimport { useState, useEffect } from 'react';\n\nfunction useDebounce<T>(value: T, delay: number): T {\n  const [debouncedValue, setDebouncedValue] = useState<T>(value);\n\n  useEffect(() => {\n    const handler = setTimeout(() => {\n      setDebouncedValue(value);\n    }, delay);\n\n    return () => {\n      clearTimeout(handler);\n    };\n  }, [value, delay]);\n\n  return debouncedValue;\n}\n\n// Usage\nconst [searchTerm, setSearchTerm] = useState('');\nconst debouncedSearchTerm = useDebounce(searchTerm, 300);\n\n// Virtual scrolling for agent list\nimport { useVirtualizer } from '@tanstack/react-virtual';\n\nfunction VirtualAgentList({ agents }) {\n  const parentRef = useRef<HTMLDivElement>(null);\n\n  const virtualizer = useVirtualizer({\n    count: agents.length,\n    getScrollElement: () => parentRef.current,\n    estimateSize: () => 100, // estimated row height\n  });\n\n  return (\n    <div ref={parentRef} className=\"h-[500px] overflow-auto\">\n      <div\n        style={{\n          height: `${virtualizer.getTotalSize()}px`,\n          width: '100%',\n          position: 'relative',\n        }}\n      >\n        {virtualizer.getVirtualItems().map((virtualRow) => (\n          <div\n            key={virtualRow.index}\n            style={{\n              position: 'absolute',\n              top: 0,\n              left: 0,\n              width: '100%',\n              height: `${virtualRow.size}px`,\n              transform: `translateY(${virtualRow.start}px)`,\n            }}\n          >\n            <AgentCard agent={agents[virtualRow.index]} />\n          </div>\n        ))}\n      </div>\n    </div>\n  );\n}\n```",
        "testStrategy": "Measure page load times before and after optimizations. Test on low-end devices to verify performance improvements. Verify lazy loading works correctly for images. Test virtual scrolling with large agent lists. Measure bundle size before and after optimizations.",
        "priority": "medium",
        "dependencies": [
          4,
          12
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 16,
        "title": "Error Handling and Fallbacks",
        "description": "Implement comprehensive error handling and fallback UI components.",
        "details": "1. Create error boundary components\n2. Implement fallback UI for API failures\n3. Add retry mechanisms for failed requests\n4. Create toast notifications for errors\n5. Implement offline detection and messaging\n6. Add graceful degradation for unsupported features\n\n```typescript\n// Error boundary component\nimport { Component, ErrorInfo, ReactNode } from 'react';\n\ninterface ErrorBoundaryProps {\n  fallback: ReactNode;\n  children: ReactNode;\n}\n\ninterface ErrorBoundaryState {\n  hasError: boolean;\n}\n\nclass ErrorBoundary extends Component<ErrorBoundaryProps, ErrorBoundaryState> {\n  constructor(props: ErrorBoundaryProps) {\n    super(props);\n    this.state = { hasError: false };\n  }\n\n  static getDerivedStateFromError(_: Error): ErrorBoundaryState {\n    return { hasError: true };\n  }\n\n  componentDidCatch(error: Error, errorInfo: ErrorInfo) {\n    console.error('Error caught by boundary:', error, errorInfo);\n  }\n\n  render() {\n    if (this.state.hasError) {\n      return this.props.fallback;\n    }\n\n    return this.props.children;\n  }\n}\n\n// Toast notification component\nimport { useState, useEffect } from 'react';\n\ninterface ToastProps {\n  message: string;\n  type: 'error' | 'success' | 'info';\n  duration?: number;\n  onClose: () => void;\n}\n\nfunction Toast({ message, type, duration = 3000, onClose }: ToastProps) {\n  useEffect(() => {\n    const timer = setTimeout(() => {\n      onClose();\n    }, duration);\n\n    return () => clearTimeout(timer);\n  }, [duration, onClose]);\n\n  return (\n    <div className={`fixed bottom-4 right-4 p-4 rounded-md ${type === 'error' ? 'bg-red-500' : type === 'success' ? 'bg-green-500' : 'bg-blue-500'} text-white`}>\n      {message}\n    </div>\n  );\n}\n\n// Offline detection hook\nfunction useOnlineStatus() {\n  const [isOnline, setIsOnline] = useState(\n    typeof navigator !== 'undefined' ? navigator.onLine : true\n  );\n\n  useEffect(() => {\n    const handleOnline = () => setIsOnline(true);\n    const handleOffline = () => setIsOnline(false);\n\n    window.addEventListener('online', handleOnline);\n    window.addEventListener('offline', handleOffline);\n\n    return () => {\n      window.removeEventListener('online', handleOnline);\n      window.removeEventListener('offline', handleOffline);\n    };\n  }, []);\n\n  return isOnline;\n}\n```",
        "testStrategy": "Test error boundary with simulated component errors. Verify fallback UI appears correctly for API failures. Test retry mechanisms for failed requests. Verify toast notifications appear and disappear correctly. Test offline detection by toggling network connection.",
        "priority": "medium",
        "dependencies": [
          8,
          10,
          12,
          13
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 17,
        "title": "Loading States and Skeleton Screens",
        "description": "Implement loading states and skeleton screens for a better user experience during data fetching.",
        "details": "1. Create skeleton components for agent cards\n2. Implement loading states for chat interface\n3. Add progress indicators for voice processing\n4. Create transition animations between states\n5. Implement loading states for initial page load\n\n```typescript\n// Skeleton loader for agent card\nfunction AgentCardSkeleton() {\n  return (\n    <div className=\"p-4 border border-border rounded-md animate-pulse\">\n      <div className=\"h-6 w-3/4 bg-card-hover rounded mb-2\"></div>\n      <div className=\"h-4 w-full bg-card-hover rounded mb-3\"></div>\n      <div className=\"flex gap-2\">\n        <div className=\"h-6 w-16 bg-card-hover rounded\"></div>\n        <div className=\"h-6 w-16 bg-card-hover rounded\"></div>\n      </div>\n    </div>\n  );\n}\n\n// Agent list with loading state\nfunction AgentList() {\n  const { agents, isLoading } = useAgents();\n  \n  if (isLoading) {\n    return (\n      <div className=\"grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-4\">\n        {[...Array(6)].map((_, i) => (\n          <AgentCardSkeleton key={i} />\n        ))}\n      </div>\n    );\n  }\n  \n  return (\n    <div className=\"grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-4\">\n      {agents.map(agent => (\n        <AgentCard key={agent.id} agent={agent} />\n      ))}\n    </div>\n  );\n}\n\n// Loading indicator for chat\nfunction ChatLoadingIndicator() {\n  return (\n    <div className=\"flex items-center justify-center p-4\">\n      <div className=\"w-8 h-8 border-4 border-primary border-t-transparent rounded-full animate-spin\"></div>\n    </div>\n  );\n}\n\n// Page transition animation\nimport { motion } from 'framer-motion';\n\nfunction PageTransition({ children }) {\n  return (\n    <motion.div\n      initial={{ opacity: 0 }}\n      animate={{ opacity: 1 }}\n      exit={{ opacity: 0 }}\n      transition={{ duration: 0.3 }}\n    >\n      {children}\n    </motion.div>\n  );\n}\n```",
        "testStrategy": "Test skeleton loaders with simulated loading states. Verify loading indicators appear during data fetching. Test transition animations between states. Ensure loading states provide a good user experience on slow connections.",
        "priority": "medium",
        "dependencies": [
          4,
          12
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 18,
        "title": "Deployment Configuration",
        "description": "Configure deployment settings for Vercel or similar CDN hosting.",
        "details": "1. Create Vercel configuration file\n2. Configure build settings\n3. Set up environment variables\n4. Configure custom domain\n5. Set up CI/CD pipeline\n6. Configure caching policies\n7. Set up monitoring and analytics\n\n```json\n// vercel.json\n{\n  \"version\": 2,\n  \"builds\": [\n    {\n      \"src\": \"package.json\",\n      \"use\": \"@vercel/next\"\n    }\n  ],\n  \"routes\": [\n    {\n      \"src\": \"/api/(.*)\",\n      \"headers\": {\n        \"cache-control\": \"public, max-age=0, must-revalidate\"\n      }\n    },\n    {\n      \"src\": \"/(.*)\",\n      \"headers\": {\n        \"cache-control\": \"public, max-age=3600, s-maxage=86400\"\n      }\n    }\n  ],\n  \"env\": {\n    \"NEXT_PUBLIC_FIREBASE_API_KEY\": \"@firebase-api-key\",\n    \"NEXT_PUBLIC_FIREBASE_AUTH_DOMAIN\": \"@firebase-auth-domain\",\n    \"NEXT_PUBLIC_FIREBASE_PROJECT_ID\": \"@firebase-project-id\",\n    \"OPENAI_API_KEY\": \"@openai-api-key\",\n    \"NEXT_PUBLIC_APP_URL\": \"@app-url\"\n  }\n}\n\n// next.config.js\nmodule.exports = {\n  reactStrictMode: true,\n  images: {\n    domains: ['firebasestorage.googleapis.com'],\n  },\n  experimental: {\n    optimizeCss: true,\n    scrollRestoration: true,\n  },\n}\n```",
        "testStrategy": "Test deployment to staging environment. Verify environment variables are correctly set. Test custom domain configuration. Verify caching policies work correctly. Test CI/CD pipeline with sample changes. Verify monitoring and analytics are working.",
        "priority": "low",
        "dependencies": [
          1,
          2,
          3,
          13
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 19,
        "title": "Progressive Web App Configuration",
        "description": "Configure the application as a Progressive Web App (PWA) for better mobile experience.",
        "details": "1. Create manifest.json file\n2. Add service worker for offline support\n3. Configure app icons\n4. Set up install prompts\n5. Configure offline fallback pages\n6. Add splash screens for various devices\n\n```json\n// public/manifest.json\n{\n  \"name\": \"Keryk AI Agent Sandbox\",\n  \"short_name\": \"Keryk Sandbox\",\n  \"description\": \"Demo platform for Keryk AI agents\",\n  \"start_url\": \"/\",\n  \"display\": \"standalone\",\n  \"background_color\": \"#0a0a0a\",\n  \"theme_color\": \"#3b82f6\",\n  \"icons\": [\n    {\n      \"src\": \"/icons/icon-192.png\",\n      \"sizes\": \"192x192\",\n      \"type\": \"image/png\"\n    },\n    {\n      \"src\": \"/icons/icon-512.png\",\n      \"sizes\": \"512x512\",\n      \"type\": \"image/png\"\n    },\n    {\n      \"src\": \"/icons/maskable-icon.png\",\n      \"sizes\": \"512x512\",\n      \"type\": \"image/png\",\n      \"purpose\": \"maskable\"\n    }\n  ]\n}\n\n// next.config.js with PWA configuration\nconst withPWA = require('next-pwa');\n\nmodule.exports = withPWA({\n  pwa: {\n    dest: 'public',\n    register: true,\n    skipWaiting: true,\n    disable: process.env.NODE_ENV === 'development'\n  },\n  // other Next.js config\n});\n```",
        "testStrategy": "Test PWA installation on various devices. Verify offline functionality works correctly. Test app icons and splash screens on different devices. Verify install prompts appear correctly. Test offline fallback pages when network is unavailable.",
        "priority": "low",
        "dependencies": [
          1,
          14,
          15
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 20,
        "title": "Final Testing and Quality Assurance",
        "description": "Conduct comprehensive testing and quality assurance to ensure the application meets all requirements.",
        "status": "done",
        "dependencies": [
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "priority": "high",
        "details": "1. Create test plan covering all features\n2. Test on various devices and browsers\n3. Verify all success metrics are met\n4. Test accessibility compliance\n5. Conduct performance testing\n6. Verify security measures\n7. Create user testing scenarios\n8. Document any issues and fixes\n\nTest Plan Outline:\n1. Authentication\n   - Test login with email/password\n   - Test anonymous access ✅\n   - Verify sandbox_access flag works\n\n2. Agent Discovery\n   - Test browsing all agents ✅\n   - Test search and filtering\n   - Verify real-time updates\n\n3. Chat Interface\n   - Test text chat functionality ✅\n   - Test voice chat functionality\n   - Test mode switching\n\n4. Mobile Experience\n   - Test on various mobile devices\n   - Verify touch interactions\n   - Test virtual keyboard handling\n\n5. Performance\n   - Measure page load times\n   - Test time to interactive\n   - Verify Lighthouse scores\n   - Measure bundle size\n\n6. Error Handling\n   - Test with network disconnection\n   - Test with API failures\n   - Verify error messages\n\n7. Accessibility\n   - Test with screen readers\n   - Verify color contrast\n   - Test keyboard navigation\n\nCompleted Infrastructure Verification:\n- Mentor Backend: Running on localhost:8080 ✅\n- Frontend: Running on localhost:3000 ✅  \n- Firebase Auth: Configured for anonymous access ✅\n- OpenAI API: Working and generating responses ✅",
        "testStrategy": "Core functionality testing has been completed successfully. Continue with manual UI testing and voice functionality testing. Execute the remaining test plan items on various devices and browsers. Document all issues found and verify fixes. Measure performance metrics against success criteria. Conduct user testing with representative users. Create final test report documenting test coverage and results.",
        "subtasks": [
          {
            "id": 1,
            "title": "Core Functionality Testing",
            "description": "Test the core functionality of the application",
            "status": "completed",
            "dependencies": [],
            "details": "Tested and verified:\n- Authentication Flow: Anonymous access\n- Agent Discovery: 2 agents loading correctly (Test Knowledge Assistant, MUTCD_TA_Specialist)\n- Agent Selection: Navigation to chat interface\n- Backend Integration: Mentor backend (port 8080) and Frontend APIs\n- Chat Functionality: Message API with OpenAI integration",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "API Testing",
            "description": "Test all API endpoints",
            "status": "completed",
            "dependencies": [],
            "details": "Verified:\n- Agent List API: Returns 2 agents correctly at http://localhost:3000/api/agents\n- Message API: Successfully tested with curl - got AI response from Test Knowledge Assistant\n- Applied fix for API service configuration (API_BASE_URL) to use window.location.origin",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Manual UI Testing",
            "description": "Conduct manual testing of the user interface",
            "status": "done",
            "dependencies": [],
            "details": "Test all UI components for proper rendering, interactions, and responsiveness across different screen sizes and devices.",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Voice Functionality Testing",
            "description": "Test voice chat functionality",
            "status": "done",
            "dependencies": [],
            "details": "Test voice input and output, voice recognition accuracy, and voice mode switching.",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Cross-browser and Cross-device Testing",
            "description": "Test application on various browsers and devices",
            "status": "done",
            "dependencies": [],
            "details": "Test on Chrome, Firefox, Safari, Edge on desktop. Test on iOS and Android devices with different screen sizes.",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Accessibility Testing",
            "description": "Test application for accessibility compliance",
            "status": "done",
            "dependencies": [],
            "details": "Test with screen readers, keyboard navigation, and verify color contrast meets WCAG standards.",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "Performance Testing",
            "description": "Measure and optimize application performance",
            "status": "done",
            "dependencies": [],
            "details": "Measure page load times, time to interactive, Lighthouse scores, and bundle size. Identify and address performance bottlenecks.",
            "testStrategy": ""
          },
          {
            "id": 8,
            "title": "Final Test Report",
            "description": "Create comprehensive test report",
            "status": "done",
            "dependencies": [],
            "details": "Document all test cases, results, issues found, fixes applied, and overall quality assessment.",
            "testStrategy": ""
          }
        ]
      }
    ],
    "metadata": {
      "created": "2025-07-04T19:54:26.105Z",
      "updated": "2025-07-05T19:29:16.753Z",
      "description": "Tasks for master context"
    }
  }
}